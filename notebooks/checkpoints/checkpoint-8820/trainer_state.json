{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 28.0,
  "eval_steps": 500,
  "global_step": 8820,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.15873015873015872,
      "grad_norm": 1.494891881942749,
      "learning_rate": 0.000198984126984127,
      "loss": 7.7863,
      "step": 50
    },
    {
      "epoch": 0.31746031746031744,
      "grad_norm": 1.9048711061477661,
      "learning_rate": 0.00019792592592592594,
      "loss": 4.9679,
      "step": 100
    },
    {
      "epoch": 0.47619047619047616,
      "grad_norm": 3.666375160217285,
      "learning_rate": 0.0001968888888888889,
      "loss": 4.6522,
      "step": 150
    },
    {
      "epoch": 0.6349206349206349,
      "grad_norm": 8.181422233581543,
      "learning_rate": 0.00019583068783068783,
      "loss": 4.5102,
      "step": 200
    },
    {
      "epoch": 0.7936507936507936,
      "grad_norm": 2.964604377746582,
      "learning_rate": 0.00019477248677248678,
      "loss": 4.4107,
      "step": 250
    },
    {
      "epoch": 0.9523809523809523,
      "grad_norm": 4.834600448608398,
      "learning_rate": 0.00019371428571428572,
      "loss": 4.3481,
      "step": 300
    },
    {
      "epoch": 1.0,
      "eval_loss": 4.286003589630127,
      "eval_runtime": 9.0203,
      "eval_samples_per_second": 11.53,
      "eval_steps_per_second": 3.88,
      "step": 315
    },
    {
      "epoch": 1.1111111111111112,
      "grad_norm": 6.29770565032959,
      "learning_rate": 0.00019265608465608467,
      "loss": 4.2917,
      "step": 350
    },
    {
      "epoch": 1.2698412698412698,
      "grad_norm": 4.251371383666992,
      "learning_rate": 0.0001915978835978836,
      "loss": 4.2347,
      "step": 400
    },
    {
      "epoch": 1.4285714285714286,
      "grad_norm": 5.790469169616699,
      "learning_rate": 0.00019056084656084656,
      "loss": 4.1874,
      "step": 450
    },
    {
      "epoch": 1.5873015873015874,
      "grad_norm": 13.229588508605957,
      "learning_rate": 0.0001895026455026455,
      "loss": 4.1814,
      "step": 500
    },
    {
      "epoch": 1.746031746031746,
      "grad_norm": 10.09781551361084,
      "learning_rate": 0.00018844444444444445,
      "loss": 4.1507,
      "step": 550
    },
    {
      "epoch": 1.9047619047619047,
      "grad_norm": 8.208017349243164,
      "learning_rate": 0.0001873862433862434,
      "loss": 4.1231,
      "step": 600
    },
    {
      "epoch": 2.0,
      "eval_loss": 4.107602119445801,
      "eval_runtime": 9.0233,
      "eval_samples_per_second": 11.526,
      "eval_steps_per_second": 3.879,
      "step": 630
    },
    {
      "epoch": 2.0634920634920633,
      "grad_norm": 6.702576160430908,
      "learning_rate": 0.00018632804232804234,
      "loss": 4.0998,
      "step": 650
    },
    {
      "epoch": 2.2222222222222223,
      "grad_norm": 14.171318054199219,
      "learning_rate": 0.00018526984126984128,
      "loss": 4.1046,
      "step": 700
    },
    {
      "epoch": 2.380952380952381,
      "grad_norm": 10.572996139526367,
      "learning_rate": 0.0001842116402116402,
      "loss": 4.0949,
      "step": 750
    },
    {
      "epoch": 2.5396825396825395,
      "grad_norm": 6.485287666320801,
      "learning_rate": 0.00018315343915343917,
      "loss": 4.056,
      "step": 800
    },
    {
      "epoch": 2.6984126984126986,
      "grad_norm": 7.7315874099731445,
      "learning_rate": 0.0001820952380952381,
      "loss": 4.0594,
      "step": 850
    },
    {
      "epoch": 2.857142857142857,
      "grad_norm": 9.237275123596191,
      "learning_rate": 0.00018103703703703706,
      "loss": 4.0485,
      "step": 900
    },
    {
      "epoch": 3.0,
      "eval_loss": 4.031806945800781,
      "eval_runtime": 9.0371,
      "eval_samples_per_second": 11.508,
      "eval_steps_per_second": 3.873,
      "step": 945
    },
    {
      "epoch": 3.015873015873016,
      "grad_norm": 10.013867378234863,
      "learning_rate": 0.00017997883597883598,
      "loss": 4.0279,
      "step": 950
    },
    {
      "epoch": 3.1746031746031744,
      "grad_norm": 9.75373649597168,
      "learning_rate": 0.00017892063492063492,
      "loss": 4.0324,
      "step": 1000
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 10.245189666748047,
      "learning_rate": 0.00017786243386243387,
      "loss": 4.0337,
      "step": 1050
    },
    {
      "epoch": 3.492063492063492,
      "grad_norm": 15.32751750946045,
      "learning_rate": 0.0001768042328042328,
      "loss": 4.0471,
      "step": 1100
    },
    {
      "epoch": 3.6507936507936507,
      "grad_norm": 7.099555969238281,
      "learning_rate": 0.00017574603174603176,
      "loss": 4.0135,
      "step": 1150
    },
    {
      "epoch": 3.8095238095238093,
      "grad_norm": 8.856364250183105,
      "learning_rate": 0.0001746878306878307,
      "loss": 4.0097,
      "step": 1200
    },
    {
      "epoch": 3.9682539682539684,
      "grad_norm": 56.622413635253906,
      "learning_rate": 0.00017362962962962964,
      "loss": 4.0159,
      "step": 1250
    },
    {
      "epoch": 4.0,
      "eval_loss": 4.018683910369873,
      "eval_runtime": 9.0141,
      "eval_samples_per_second": 11.537,
      "eval_steps_per_second": 3.883,
      "step": 1260
    },
    {
      "epoch": 4.1269841269841265,
      "grad_norm": 10.571208953857422,
      "learning_rate": 0.0001725714285714286,
      "loss": 3.9973,
      "step": 1300
    },
    {
      "epoch": 4.285714285714286,
      "grad_norm": 10.261955261230469,
      "learning_rate": 0.0001715132275132275,
      "loss": 4.013,
      "step": 1350
    },
    {
      "epoch": 4.444444444444445,
      "grad_norm": 6.891416072845459,
      "learning_rate": 0.00017045502645502648,
      "loss": 3.9989,
      "step": 1400
    },
    {
      "epoch": 4.603174603174603,
      "grad_norm": 18.24308204650879,
      "learning_rate": 0.0001693968253968254,
      "loss": 4.0045,
      "step": 1450
    },
    {
      "epoch": 4.761904761904762,
      "grad_norm": 9.0672607421875,
      "learning_rate": 0.00016833862433862434,
      "loss": 3.9986,
      "step": 1500
    },
    {
      "epoch": 4.920634920634921,
      "grad_norm": 9.759623527526855,
      "learning_rate": 0.00016728042328042328,
      "loss": 3.9967,
      "step": 1550
    },
    {
      "epoch": 5.0,
      "eval_loss": 3.990170955657959,
      "eval_runtime": 9.0205,
      "eval_samples_per_second": 11.529,
      "eval_steps_per_second": 3.88,
      "step": 1575
    },
    {
      "epoch": 5.079365079365079,
      "grad_norm": 6.257742881774902,
      "learning_rate": 0.00016622222222222223,
      "loss": 3.9818,
      "step": 1600
    },
    {
      "epoch": 5.238095238095238,
      "grad_norm": 30.869901657104492,
      "learning_rate": 0.00016516402116402117,
      "loss": 3.9932,
      "step": 1650
    },
    {
      "epoch": 5.396825396825397,
      "grad_norm": 10.549936294555664,
      "learning_rate": 0.00016412698412698412,
      "loss": 3.9835,
      "step": 1700
    },
    {
      "epoch": 5.555555555555555,
      "grad_norm": 8.759515762329102,
      "learning_rate": 0.0001630687830687831,
      "loss": 3.9852,
      "step": 1750
    },
    {
      "epoch": 5.714285714285714,
      "grad_norm": 5.142183780670166,
      "learning_rate": 0.000162010582010582,
      "loss": 3.9917,
      "step": 1800
    },
    {
      "epoch": 5.8730158730158735,
      "grad_norm": 15.700270652770996,
      "learning_rate": 0.00016095238095238096,
      "loss": 3.9849,
      "step": 1850
    },
    {
      "epoch": 6.0,
      "eval_loss": 3.9780118465423584,
      "eval_runtime": 9.019,
      "eval_samples_per_second": 11.531,
      "eval_steps_per_second": 3.881,
      "step": 1890
    },
    {
      "epoch": 6.031746031746032,
      "grad_norm": 8.143084526062012,
      "learning_rate": 0.0001598941798941799,
      "loss": 3.9812,
      "step": 1900
    },
    {
      "epoch": 6.190476190476191,
      "grad_norm": 9.175115585327148,
      "learning_rate": 0.00015883597883597884,
      "loss": 3.9663,
      "step": 1950
    },
    {
      "epoch": 6.349206349206349,
      "grad_norm": 9.744301795959473,
      "learning_rate": 0.0001577777777777778,
      "loss": 3.9668,
      "step": 2000
    },
    {
      "epoch": 6.507936507936508,
      "grad_norm": 14.512730598449707,
      "learning_rate": 0.00015671957671957673,
      "loss": 3.9745,
      "step": 2050
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 27.26902961730957,
      "learning_rate": 0.00015566137566137568,
      "loss": 3.969,
      "step": 2100
    },
    {
      "epoch": 6.825396825396825,
      "grad_norm": 9.221705436706543,
      "learning_rate": 0.00015460317460317462,
      "loss": 3.9854,
      "step": 2150
    },
    {
      "epoch": 6.984126984126984,
      "grad_norm": 16.480825424194336,
      "learning_rate": 0.00015354497354497354,
      "loss": 3.9692,
      "step": 2200
    },
    {
      "epoch": 7.0,
      "eval_loss": 3.9754114151000977,
      "eval_runtime": 9.0208,
      "eval_samples_per_second": 11.529,
      "eval_steps_per_second": 3.88,
      "step": 2205
    },
    {
      "epoch": 7.142857142857143,
      "grad_norm": 18.249515533447266,
      "learning_rate": 0.0001524867724867725,
      "loss": 3.9494,
      "step": 2250
    },
    {
      "epoch": 7.301587301587301,
      "grad_norm": 8.989677429199219,
      "learning_rate": 0.00015142857142857143,
      "loss": 3.967,
      "step": 2300
    },
    {
      "epoch": 7.4603174603174605,
      "grad_norm": 11.299367904663086,
      "learning_rate": 0.00015037037037037037,
      "loss": 3.9669,
      "step": 2350
    },
    {
      "epoch": 7.619047619047619,
      "grad_norm": 12.924110412597656,
      "learning_rate": 0.00014931216931216932,
      "loss": 3.9851,
      "step": 2400
    },
    {
      "epoch": 7.777777777777778,
      "grad_norm": 7.2202630043029785,
      "learning_rate": 0.00014825396825396826,
      "loss": 3.9451,
      "step": 2450
    },
    {
      "epoch": 7.936507936507937,
      "grad_norm": 8.386320114135742,
      "learning_rate": 0.0001471957671957672,
      "loss": 3.9593,
      "step": 2500
    },
    {
      "epoch": 8.0,
      "eval_loss": 3.9561870098114014,
      "eval_runtime": 9.0189,
      "eval_samples_per_second": 11.531,
      "eval_steps_per_second": 3.881,
      "step": 2520
    },
    {
      "epoch": 8.095238095238095,
      "grad_norm": 6.6991682052612305,
      "learning_rate": 0.00014613756613756615,
      "loss": 3.9381,
      "step": 2550
    },
    {
      "epoch": 8.253968253968253,
      "grad_norm": 11.438495635986328,
      "learning_rate": 0.0001450793650793651,
      "loss": 3.9537,
      "step": 2600
    },
    {
      "epoch": 8.412698412698413,
      "grad_norm": 11.125670433044434,
      "learning_rate": 0.00014402116402116404,
      "loss": 3.9494,
      "step": 2650
    },
    {
      "epoch": 8.571428571428571,
      "grad_norm": 5.755794525146484,
      "learning_rate": 0.00014296296296296295,
      "loss": 3.9718,
      "step": 2700
    },
    {
      "epoch": 8.73015873015873,
      "grad_norm": 13.142865180969238,
      "learning_rate": 0.00014190476190476193,
      "loss": 3.962,
      "step": 2750
    },
    {
      "epoch": 8.88888888888889,
      "grad_norm": 8.405206680297852,
      "learning_rate": 0.00014084656084656084,
      "loss": 3.9467,
      "step": 2800
    },
    {
      "epoch": 9.0,
      "eval_loss": 3.9585671424865723,
      "eval_runtime": 9.0299,
      "eval_samples_per_second": 11.517,
      "eval_steps_per_second": 3.876,
      "step": 2835
    },
    {
      "epoch": 9.047619047619047,
      "grad_norm": 6.855636119842529,
      "learning_rate": 0.00013978835978835981,
      "loss": 3.9495,
      "step": 2850
    },
    {
      "epoch": 9.206349206349206,
      "grad_norm": 8.209236145019531,
      "learning_rate": 0.00013873015873015873,
      "loss": 3.9493,
      "step": 2900
    },
    {
      "epoch": 9.365079365079366,
      "grad_norm": 5.839914321899414,
      "learning_rate": 0.00013767195767195768,
      "loss": 3.9368,
      "step": 2950
    },
    {
      "epoch": 9.523809523809524,
      "grad_norm": 7.869211673736572,
      "learning_rate": 0.00013661375661375662,
      "loss": 3.9459,
      "step": 3000
    },
    {
      "epoch": 9.682539682539682,
      "grad_norm": 8.1765718460083,
      "learning_rate": 0.00013555555555555556,
      "loss": 3.9362,
      "step": 3050
    },
    {
      "epoch": 9.841269841269842,
      "grad_norm": 26.355134963989258,
      "learning_rate": 0.0001344973544973545,
      "loss": 3.9541,
      "step": 3100
    },
    {
      "epoch": 10.0,
      "grad_norm": 15.4932861328125,
      "learning_rate": 0.00013343915343915345,
      "loss": 3.9519,
      "step": 3150
    },
    {
      "epoch": 10.0,
      "eval_loss": 3.951902151107788,
      "eval_runtime": 9.0188,
      "eval_samples_per_second": 11.531,
      "eval_steps_per_second": 3.881,
      "step": 3150
    },
    {
      "epoch": 10.158730158730158,
      "grad_norm": 7.0226216316223145,
      "learning_rate": 0.00013238095238095237,
      "loss": 3.9476,
      "step": 3200
    },
    {
      "epoch": 10.317460317460318,
      "grad_norm": 12.830190658569336,
      "learning_rate": 0.00013132275132275134,
      "loss": 3.9432,
      "step": 3250
    },
    {
      "epoch": 10.476190476190476,
      "grad_norm": 5.952112197875977,
      "learning_rate": 0.00013026455026455026,
      "loss": 3.9359,
      "step": 3300
    },
    {
      "epoch": 10.634920634920634,
      "grad_norm": 4.927724838256836,
      "learning_rate": 0.00012920634920634923,
      "loss": 3.9305,
      "step": 3350
    },
    {
      "epoch": 10.793650793650794,
      "grad_norm": 12.95725154876709,
      "learning_rate": 0.00012814814814814815,
      "loss": 3.9317,
      "step": 3400
    },
    {
      "epoch": 10.952380952380953,
      "grad_norm": 8.891865730285645,
      "learning_rate": 0.0001270899470899471,
      "loss": 3.9362,
      "step": 3450
    },
    {
      "epoch": 11.0,
      "eval_loss": 3.9368185997009277,
      "eval_runtime": 9.0206,
      "eval_samples_per_second": 11.529,
      "eval_steps_per_second": 3.88,
      "step": 3465
    },
    {
      "epoch": 11.11111111111111,
      "grad_norm": 11.826885223388672,
      "learning_rate": 0.00012603174603174604,
      "loss": 3.9241,
      "step": 3500
    },
    {
      "epoch": 11.26984126984127,
      "grad_norm": 8.865262985229492,
      "learning_rate": 0.00012497354497354498,
      "loss": 3.9346,
      "step": 3550
    },
    {
      "epoch": 11.428571428571429,
      "grad_norm": 5.674790382385254,
      "learning_rate": 0.00012391534391534393,
      "loss": 3.9361,
      "step": 3600
    },
    {
      "epoch": 11.587301587301587,
      "grad_norm": 10.990160942077637,
      "learning_rate": 0.00012285714285714287,
      "loss": 3.9279,
      "step": 3650
    },
    {
      "epoch": 11.746031746031747,
      "grad_norm": 9.457619667053223,
      "learning_rate": 0.0001217989417989418,
      "loss": 3.9406,
      "step": 3700
    },
    {
      "epoch": 11.904761904761905,
      "grad_norm": 10.60229206085205,
      "learning_rate": 0.00012074074074074076,
      "loss": 3.9267,
      "step": 3750
    },
    {
      "epoch": 12.0,
      "eval_loss": 3.932612180709839,
      "eval_runtime": 9.0549,
      "eval_samples_per_second": 11.486,
      "eval_steps_per_second": 3.865,
      "step": 3780
    },
    {
      "epoch": 12.063492063492063,
      "grad_norm": 6.146290302276611,
      "learning_rate": 0.00011968253968253969,
      "loss": 3.9442,
      "step": 3800
    },
    {
      "epoch": 12.222222222222221,
      "grad_norm": 4.9890289306640625,
      "learning_rate": 0.00011862433862433863,
      "loss": 3.938,
      "step": 3850
    },
    {
      "epoch": 12.380952380952381,
      "grad_norm": 10.40371036529541,
      "learning_rate": 0.00011756613756613756,
      "loss": 3.9289,
      "step": 3900
    },
    {
      "epoch": 12.53968253968254,
      "grad_norm": 7.448307514190674,
      "learning_rate": 0.00011650793650793652,
      "loss": 3.9135,
      "step": 3950
    },
    {
      "epoch": 12.698412698412698,
      "grad_norm": 12.159561157226562,
      "learning_rate": 0.00011544973544973545,
      "loss": 3.9327,
      "step": 4000
    },
    {
      "epoch": 12.857142857142858,
      "grad_norm": 11.044797897338867,
      "learning_rate": 0.00011439153439153441,
      "loss": 3.9249,
      "step": 4050
    },
    {
      "epoch": 13.0,
      "eval_loss": 3.9310057163238525,
      "eval_runtime": 9.0214,
      "eval_samples_per_second": 11.528,
      "eval_steps_per_second": 3.88,
      "step": 4095
    },
    {
      "epoch": 13.015873015873016,
      "grad_norm": 5.02562141418457,
      "learning_rate": 0.00011333333333333334,
      "loss": 3.9171,
      "step": 4100
    },
    {
      "epoch": 13.174603174603174,
      "grad_norm": 7.88499116897583,
      "learning_rate": 0.00011227513227513229,
      "loss": 3.9187,
      "step": 4150
    },
    {
      "epoch": 13.333333333333334,
      "grad_norm": 5.015169620513916,
      "learning_rate": 0.00011121693121693122,
      "loss": 3.9304,
      "step": 4200
    },
    {
      "epoch": 13.492063492063492,
      "grad_norm": 13.410806655883789,
      "learning_rate": 0.00011015873015873017,
      "loss": 3.9312,
      "step": 4250
    },
    {
      "epoch": 13.65079365079365,
      "grad_norm": 8.811033248901367,
      "learning_rate": 0.0001091005291005291,
      "loss": 3.9272,
      "step": 4300
    },
    {
      "epoch": 13.80952380952381,
      "grad_norm": 9.37540054321289,
      "learning_rate": 0.00010804232804232805,
      "loss": 3.9315,
      "step": 4350
    },
    {
      "epoch": 13.968253968253968,
      "grad_norm": 5.687538146972656,
      "learning_rate": 0.00010698412698412698,
      "loss": 3.9048,
      "step": 4400
    },
    {
      "epoch": 14.0,
      "eval_loss": 3.9285337924957275,
      "eval_runtime": 9.017,
      "eval_samples_per_second": 11.534,
      "eval_steps_per_second": 3.882,
      "step": 4410
    },
    {
      "epoch": 14.126984126984127,
      "grad_norm": 18.352773666381836,
      "learning_rate": 0.00010592592592592594,
      "loss": 3.898,
      "step": 4450
    },
    {
      "epoch": 14.285714285714286,
      "grad_norm": 5.779170513153076,
      "learning_rate": 0.00010486772486772487,
      "loss": 3.925,
      "step": 4500
    },
    {
      "epoch": 14.444444444444445,
      "grad_norm": 8.351526260375977,
      "learning_rate": 0.00010380952380952383,
      "loss": 3.9173,
      "step": 4550
    },
    {
      "epoch": 14.603174603174603,
      "grad_norm": 18.448955535888672,
      "learning_rate": 0.00010275132275132276,
      "loss": 3.93,
      "step": 4600
    },
    {
      "epoch": 14.761904761904763,
      "grad_norm": 10.03300666809082,
      "learning_rate": 0.0001016931216931217,
      "loss": 3.9258,
      "step": 4650
    },
    {
      "epoch": 14.920634920634921,
      "grad_norm": 15.892407417297363,
      "learning_rate": 0.00010063492063492063,
      "loss": 3.9167,
      "step": 4700
    },
    {
      "epoch": 15.0,
      "eval_loss": 3.92590594291687,
      "eval_runtime": 9.0385,
      "eval_samples_per_second": 11.506,
      "eval_steps_per_second": 3.872,
      "step": 4725
    },
    {
      "epoch": 15.079365079365079,
      "grad_norm": 11.437638282775879,
      "learning_rate": 9.957671957671958e-05,
      "loss": 3.9166,
      "step": 4750
    },
    {
      "epoch": 15.238095238095237,
      "grad_norm": 9.688976287841797,
      "learning_rate": 9.851851851851852e-05,
      "loss": 3.9223,
      "step": 4800
    },
    {
      "epoch": 15.396825396825397,
      "grad_norm": 9.28410816192627,
      "learning_rate": 9.746031746031747e-05,
      "loss": 3.9165,
      "step": 4850
    },
    {
      "epoch": 15.555555555555555,
      "grad_norm": 9.771995544433594,
      "learning_rate": 9.640211640211641e-05,
      "loss": 3.9203,
      "step": 4900
    },
    {
      "epoch": 15.714285714285714,
      "grad_norm": 8.995126724243164,
      "learning_rate": 9.534391534391534e-05,
      "loss": 3.917,
      "step": 4950
    },
    {
      "epoch": 15.873015873015873,
      "grad_norm": 11.101617813110352,
      "learning_rate": 9.428571428571429e-05,
      "loss": 3.9144,
      "step": 5000
    },
    {
      "epoch": 16.0,
      "eval_loss": 3.9193296432495117,
      "eval_runtime": 9.0417,
      "eval_samples_per_second": 11.502,
      "eval_steps_per_second": 3.871,
      "step": 5040
    },
    {
      "epoch": 16.03174603174603,
      "grad_norm": 6.1735687255859375,
      "learning_rate": 9.322751322751323e-05,
      "loss": 3.8929,
      "step": 5050
    },
    {
      "epoch": 16.19047619047619,
      "grad_norm": 9.363092422485352,
      "learning_rate": 9.216931216931217e-05,
      "loss": 3.9185,
      "step": 5100
    },
    {
      "epoch": 16.349206349206348,
      "grad_norm": 11.832559585571289,
      "learning_rate": 9.111111111111112e-05,
      "loss": 3.9109,
      "step": 5150
    },
    {
      "epoch": 16.507936507936506,
      "grad_norm": 12.657856941223145,
      "learning_rate": 9.005291005291005e-05,
      "loss": 3.9067,
      "step": 5200
    },
    {
      "epoch": 16.666666666666668,
      "grad_norm": 12.57715892791748,
      "learning_rate": 8.8994708994709e-05,
      "loss": 3.9096,
      "step": 5250
    },
    {
      "epoch": 16.825396825396826,
      "grad_norm": 11.982172012329102,
      "learning_rate": 8.793650793650794e-05,
      "loss": 3.9142,
      "step": 5300
    },
    {
      "epoch": 16.984126984126984,
      "grad_norm": 17.356672286987305,
      "learning_rate": 8.687830687830688e-05,
      "loss": 3.9154,
      "step": 5350
    },
    {
      "epoch": 17.0,
      "eval_loss": 3.9190943241119385,
      "eval_runtime": 9.0549,
      "eval_samples_per_second": 11.485,
      "eval_steps_per_second": 3.865,
      "step": 5355
    },
    {
      "epoch": 17.142857142857142,
      "grad_norm": 8.283586502075195,
      "learning_rate": 8.582010582010583e-05,
      "loss": 3.9096,
      "step": 5400
    },
    {
      "epoch": 17.3015873015873,
      "grad_norm": 6.765774250030518,
      "learning_rate": 8.476190476190477e-05,
      "loss": 3.9041,
      "step": 5450
    },
    {
      "epoch": 17.46031746031746,
      "grad_norm": 8.591376304626465,
      "learning_rate": 8.37037037037037e-05,
      "loss": 3.9094,
      "step": 5500
    },
    {
      "epoch": 17.61904761904762,
      "grad_norm": 4.984786510467529,
      "learning_rate": 8.264550264550265e-05,
      "loss": 3.9151,
      "step": 5550
    },
    {
      "epoch": 17.77777777777778,
      "grad_norm": 9.030062675476074,
      "learning_rate": 8.158730158730159e-05,
      "loss": 3.9087,
      "step": 5600
    },
    {
      "epoch": 17.936507936507937,
      "grad_norm": 10.870813369750977,
      "learning_rate": 8.052910052910053e-05,
      "loss": 3.9214,
      "step": 5650
    },
    {
      "epoch": 18.0,
      "eval_loss": 3.91497802734375,
      "eval_runtime": 9.0271,
      "eval_samples_per_second": 11.521,
      "eval_steps_per_second": 3.877,
      "step": 5670
    },
    {
      "epoch": 18.095238095238095,
      "grad_norm": 6.8355302810668945,
      "learning_rate": 7.947089947089948e-05,
      "loss": 3.9009,
      "step": 5700
    },
    {
      "epoch": 18.253968253968253,
      "grad_norm": 7.582409858703613,
      "learning_rate": 7.841269841269841e-05,
      "loss": 3.9133,
      "step": 5750
    },
    {
      "epoch": 18.41269841269841,
      "grad_norm": 4.911853790283203,
      "learning_rate": 7.735449735449735e-05,
      "loss": 3.9035,
      "step": 5800
    },
    {
      "epoch": 18.571428571428573,
      "grad_norm": 5.8459601402282715,
      "learning_rate": 7.62962962962963e-05,
      "loss": 3.9212,
      "step": 5850
    },
    {
      "epoch": 18.73015873015873,
      "grad_norm": 10.368398666381836,
      "learning_rate": 7.523809523809524e-05,
      "loss": 3.8989,
      "step": 5900
    },
    {
      "epoch": 18.88888888888889,
      "grad_norm": 3.9922475814819336,
      "learning_rate": 7.417989417989419e-05,
      "loss": 3.8995,
      "step": 5950
    },
    {
      "epoch": 19.0,
      "eval_loss": 3.9151365756988525,
      "eval_runtime": 9.0202,
      "eval_samples_per_second": 11.53,
      "eval_steps_per_second": 3.88,
      "step": 5985
    },
    {
      "epoch": 19.047619047619047,
      "grad_norm": 5.396777153015137,
      "learning_rate": 7.312169312169313e-05,
      "loss": 3.9093,
      "step": 6000
    },
    {
      "epoch": 19.206349206349206,
      "grad_norm": 9.023472785949707,
      "learning_rate": 7.206349206349206e-05,
      "loss": 3.8996,
      "step": 6050
    },
    {
      "epoch": 19.365079365079364,
      "grad_norm": 6.444408893585205,
      "learning_rate": 7.1005291005291e-05,
      "loss": 3.8926,
      "step": 6100
    },
    {
      "epoch": 19.523809523809526,
      "grad_norm": 13.513410568237305,
      "learning_rate": 6.994708994708995e-05,
      "loss": 3.9179,
      "step": 6150
    },
    {
      "epoch": 19.682539682539684,
      "grad_norm": 5.632240295410156,
      "learning_rate": 6.88888888888889e-05,
      "loss": 3.9093,
      "step": 6200
    },
    {
      "epoch": 19.841269841269842,
      "grad_norm": 6.922146797180176,
      "learning_rate": 6.783068783068784e-05,
      "loss": 3.8911,
      "step": 6250
    },
    {
      "epoch": 20.0,
      "grad_norm": 7.278012752532959,
      "learning_rate": 6.677248677248677e-05,
      "loss": 3.9136,
      "step": 6300
    },
    {
      "epoch": 20.0,
      "eval_loss": 3.9107871055603027,
      "eval_runtime": 9.0165,
      "eval_samples_per_second": 11.534,
      "eval_steps_per_second": 3.882,
      "step": 6300
    },
    {
      "epoch": 20.158730158730158,
      "grad_norm": 6.903871059417725,
      "learning_rate": 6.571428571428571e-05,
      "loss": 3.9,
      "step": 6350
    },
    {
      "epoch": 20.317460317460316,
      "grad_norm": 6.399582386016846,
      "learning_rate": 6.465608465608466e-05,
      "loss": 3.9056,
      "step": 6400
    },
    {
      "epoch": 20.476190476190474,
      "grad_norm": 8.120527267456055,
      "learning_rate": 6.35978835978836e-05,
      "loss": 3.9088,
      "step": 6450
    },
    {
      "epoch": 20.634920634920636,
      "grad_norm": 4.161581993103027,
      "learning_rate": 6.253968253968255e-05,
      "loss": 3.9001,
      "step": 6500
    },
    {
      "epoch": 20.793650793650794,
      "grad_norm": 8.79693603515625,
      "learning_rate": 6.148148148148148e-05,
      "loss": 3.8939,
      "step": 6550
    },
    {
      "epoch": 20.952380952380953,
      "grad_norm": 5.861053943634033,
      "learning_rate": 6.042328042328043e-05,
      "loss": 3.9091,
      "step": 6600
    },
    {
      "epoch": 21.0,
      "eval_loss": 3.9102578163146973,
      "eval_runtime": 9.0201,
      "eval_samples_per_second": 11.53,
      "eval_steps_per_second": 3.88,
      "step": 6615
    },
    {
      "epoch": 21.11111111111111,
      "grad_norm": 6.591691970825195,
      "learning_rate": 5.936507936507937e-05,
      "loss": 3.9092,
      "step": 6650
    },
    {
      "epoch": 21.26984126984127,
      "grad_norm": 8.187666893005371,
      "learning_rate": 5.830687830687831e-05,
      "loss": 3.8931,
      "step": 6700
    },
    {
      "epoch": 21.428571428571427,
      "grad_norm": 11.429922103881836,
      "learning_rate": 5.724867724867725e-05,
      "loss": 3.9024,
      "step": 6750
    },
    {
      "epoch": 21.58730158730159,
      "grad_norm": 7.080821514129639,
      "learning_rate": 5.619047619047619e-05,
      "loss": 3.8946,
      "step": 6800
    },
    {
      "epoch": 21.746031746031747,
      "grad_norm": 5.086606025695801,
      "learning_rate": 5.513227513227514e-05,
      "loss": 3.9112,
      "step": 6850
    },
    {
      "epoch": 21.904761904761905,
      "grad_norm": 5.816371440887451,
      "learning_rate": 5.4074074074074075e-05,
      "loss": 3.9007,
      "step": 6900
    },
    {
      "epoch": 22.0,
      "eval_loss": 3.9079337120056152,
      "eval_runtime": 9.0141,
      "eval_samples_per_second": 11.538,
      "eval_steps_per_second": 3.883,
      "step": 6930
    },
    {
      "epoch": 22.063492063492063,
      "grad_norm": 6.010434150695801,
      "learning_rate": 5.301587301587302e-05,
      "loss": 3.8971,
      "step": 6950
    },
    {
      "epoch": 22.22222222222222,
      "grad_norm": 5.318981647491455,
      "learning_rate": 5.1957671957671964e-05,
      "loss": 3.889,
      "step": 7000
    },
    {
      "epoch": 22.38095238095238,
      "grad_norm": 9.474165916442871,
      "learning_rate": 5.08994708994709e-05,
      "loss": 3.8999,
      "step": 7050
    },
    {
      "epoch": 22.53968253968254,
      "grad_norm": 7.9229254722595215,
      "learning_rate": 4.9841269841269845e-05,
      "loss": 3.9016,
      "step": 7100
    },
    {
      "epoch": 22.6984126984127,
      "grad_norm": 3.9233832359313965,
      "learning_rate": 4.878306878306878e-05,
      "loss": 3.9113,
      "step": 7150
    },
    {
      "epoch": 22.857142857142858,
      "grad_norm": 10.834219932556152,
      "learning_rate": 4.772486772486773e-05,
      "loss": 3.9027,
      "step": 7200
    },
    {
      "epoch": 23.0,
      "eval_loss": 3.907890796661377,
      "eval_runtime": 9.0847,
      "eval_samples_per_second": 11.448,
      "eval_steps_per_second": 3.853,
      "step": 7245
    },
    {
      "epoch": 23.015873015873016,
      "grad_norm": 6.092130184173584,
      "learning_rate": 4.666666666666667e-05,
      "loss": 3.8954,
      "step": 7250
    },
    {
      "epoch": 23.174603174603174,
      "grad_norm": 7.891532897949219,
      "learning_rate": 4.560846560846561e-05,
      "loss": 3.8928,
      "step": 7300
    },
    {
      "epoch": 23.333333333333332,
      "grad_norm": 10.488699913024902,
      "learning_rate": 4.4550264550264553e-05,
      "loss": 3.8914,
      "step": 7350
    },
    {
      "epoch": 23.49206349206349,
      "grad_norm": 5.370089530944824,
      "learning_rate": 4.34920634920635e-05,
      "loss": 3.9017,
      "step": 7400
    },
    {
      "epoch": 23.650793650793652,
      "grad_norm": 4.643113613128662,
      "learning_rate": 4.2433862433862435e-05,
      "loss": 3.8925,
      "step": 7450
    },
    {
      "epoch": 23.80952380952381,
      "grad_norm": 3.927748441696167,
      "learning_rate": 4.137566137566138e-05,
      "loss": 3.9074,
      "step": 7500
    },
    {
      "epoch": 23.96825396825397,
      "grad_norm": 7.419151782989502,
      "learning_rate": 4.031746031746032e-05,
      "loss": 3.8953,
      "step": 7550
    },
    {
      "epoch": 24.0,
      "eval_loss": 3.906200647354126,
      "eval_runtime": 9.0168,
      "eval_samples_per_second": 11.534,
      "eval_steps_per_second": 3.882,
      "step": 7560
    },
    {
      "epoch": 24.126984126984127,
      "grad_norm": 3.212099075317383,
      "learning_rate": 3.925925925925926e-05,
      "loss": 3.8997,
      "step": 7600
    },
    {
      "epoch": 24.285714285714285,
      "grad_norm": 4.767002582550049,
      "learning_rate": 3.8201058201058206e-05,
      "loss": 3.8969,
      "step": 7650
    },
    {
      "epoch": 24.444444444444443,
      "grad_norm": 6.589860439300537,
      "learning_rate": 3.7142857142857143e-05,
      "loss": 3.8915,
      "step": 7700
    },
    {
      "epoch": 24.603174603174605,
      "grad_norm": 4.722933292388916,
      "learning_rate": 3.608465608465609e-05,
      "loss": 3.8897,
      "step": 7750
    },
    {
      "epoch": 24.761904761904763,
      "grad_norm": 4.211705207824707,
      "learning_rate": 3.502645502645503e-05,
      "loss": 3.9015,
      "step": 7800
    },
    {
      "epoch": 24.92063492063492,
      "grad_norm": 4.307190418243408,
      "learning_rate": 3.396825396825397e-05,
      "loss": 3.9039,
      "step": 7850
    },
    {
      "epoch": 25.0,
      "eval_loss": 3.9069037437438965,
      "eval_runtime": 9.0228,
      "eval_samples_per_second": 11.526,
      "eval_steps_per_second": 3.879,
      "step": 7875
    },
    {
      "epoch": 25.07936507936508,
      "grad_norm": 8.394179344177246,
      "learning_rate": 3.2910052910052914e-05,
      "loss": 3.8988,
      "step": 7900
    },
    {
      "epoch": 25.238095238095237,
      "grad_norm": 3.252204179763794,
      "learning_rate": 3.185185185185185e-05,
      "loss": 3.8944,
      "step": 7950
    },
    {
      "epoch": 25.396825396825395,
      "grad_norm": 5.49078893661499,
      "learning_rate": 3.0793650793650796e-05,
      "loss": 3.9033,
      "step": 8000
    },
    {
      "epoch": 25.555555555555557,
      "grad_norm": 4.962867736816406,
      "learning_rate": 2.973544973544974e-05,
      "loss": 3.8801,
      "step": 8050
    },
    {
      "epoch": 25.714285714285715,
      "grad_norm": 8.348755836486816,
      "learning_rate": 2.867724867724868e-05,
      "loss": 3.8902,
      "step": 8100
    },
    {
      "epoch": 25.873015873015873,
      "grad_norm": 7.625482082366943,
      "learning_rate": 2.7619047619047622e-05,
      "loss": 3.9015,
      "step": 8150
    },
    {
      "epoch": 26.0,
      "eval_loss": 3.903942346572876,
      "eval_runtime": 9.018,
      "eval_samples_per_second": 11.533,
      "eval_steps_per_second": 3.881,
      "step": 8190
    },
    {
      "epoch": 26.03174603174603,
      "grad_norm": 3.981520891189575,
      "learning_rate": 2.6560846560846563e-05,
      "loss": 3.8871,
      "step": 8200
    },
    {
      "epoch": 26.19047619047619,
      "grad_norm": 6.765430450439453,
      "learning_rate": 2.5502645502645507e-05,
      "loss": 3.9016,
      "step": 8250
    },
    {
      "epoch": 26.349206349206348,
      "grad_norm": 4.070786476135254,
      "learning_rate": 2.4444444444444445e-05,
      "loss": 3.891,
      "step": 8300
    },
    {
      "epoch": 26.507936507936506,
      "grad_norm": 6.055301189422607,
      "learning_rate": 2.3386243386243386e-05,
      "loss": 3.8932,
      "step": 8350
    },
    {
      "epoch": 26.666666666666668,
      "grad_norm": 6.123738765716553,
      "learning_rate": 2.2328042328042327e-05,
      "loss": 3.8955,
      "step": 8400
    },
    {
      "epoch": 26.825396825396826,
      "grad_norm": 4.128600120544434,
      "learning_rate": 2.126984126984127e-05,
      "loss": 3.8893,
      "step": 8450
    },
    {
      "epoch": 26.984126984126984,
      "grad_norm": 4.059481620788574,
      "learning_rate": 2.0211640211640212e-05,
      "loss": 3.8897,
      "step": 8500
    },
    {
      "epoch": 27.0,
      "eval_loss": 3.904120922088623,
      "eval_runtime": 9.0168,
      "eval_samples_per_second": 11.534,
      "eval_steps_per_second": 3.882,
      "step": 8505
    },
    {
      "epoch": 27.142857142857142,
      "grad_norm": 4.180246353149414,
      "learning_rate": 1.9153439153439153e-05,
      "loss": 3.8951,
      "step": 8550
    },
    {
      "epoch": 27.3015873015873,
      "grad_norm": 3.7182984352111816,
      "learning_rate": 1.8095238095238094e-05,
      "loss": 3.8922,
      "step": 8600
    },
    {
      "epoch": 27.46031746031746,
      "grad_norm": 3.1413159370422363,
      "learning_rate": 1.7037037037037038e-05,
      "loss": 3.8941,
      "step": 8650
    },
    {
      "epoch": 27.61904761904762,
      "grad_norm": 4.099290370941162,
      "learning_rate": 1.597883597883598e-05,
      "loss": 3.8914,
      "step": 8700
    },
    {
      "epoch": 27.77777777777778,
      "grad_norm": 4.0019965171813965,
      "learning_rate": 1.4920634920634922e-05,
      "loss": 3.8945,
      "step": 8750
    },
    {
      "epoch": 27.936507936507937,
      "grad_norm": 3.7392969131469727,
      "learning_rate": 1.3862433862433863e-05,
      "loss": 3.8901,
      "step": 8800
    },
    {
      "epoch": 28.0,
      "eval_loss": 3.9029994010925293,
      "eval_runtime": 9.0274,
      "eval_samples_per_second": 11.52,
      "eval_steps_per_second": 3.877,
      "step": 8820
    }
  ],
  "logging_steps": 50,
  "max_steps": 9450,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 30,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.2249507462774784e+17,
  "train_batch_size": 3,
  "trial_name": null,
  "trial_params": null
}
